import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
import time
import os
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from scipy.stats import pearsonr

# -------------------- Hyperparameters (PINN-GRU) --------------------
GRU_UNITS = 128
DENSE_UNITS_1 = 256
DENSE_UNITS_2 = 512
DENSE_UNITS_3 = 256
DROPOUT_RATE = 0.4
LEARNING_RATE = 0.0001
BATCH_SIZE = 32
EPOCHS = 1000  # Default epochs, user can adjust in UI # Increased default epoch
PHYSICS_LOSS_WEIGHT = 0.1
NUM_LAGGED_FEATURES = 12
EPOCH_RANGE = list(range(1, 1001)) # Epoch range for slider

# -------------------- Physics-Informed Loss, Attention Layer, Custom Loss, PINNModel (Corrected get_config - Manual Tuple) --------------------
def water_balance_loss(y_true, y_pred, inputs):
Â Â Â  pcp, temp_max, temp_min = inputs[:, 0, 0], inputs[:, 0, 1], inputs[:, 0, 2]
Â Â Â  et = 0.0023 * (temp_max - temp_min) * (temp_max + temp_min)
Â Â Â  predicted_Q = y_pred
Â Â Â  balance_term = pcp - (et + predicted_Q)
Â Â Â  return tf.reduce_mean(tf.square(balance_term))

class Attention(tf.keras.layers.Layer):
Â Â Â  def __init__(self, **kwargs):
Â Â Â Â Â Â Â  super(Attention, self).__init__(**kwargs)

Â Â Â  def build(self, input_shape):
Â Â Â Â Â Â Â  self.W = self.add_weight(name="att_weight", shape=(input_shape[-1], input_shape[-1]), initializer="glorot_uniform", trainable=True)
Â Â Â Â Â Â Â  self.b = self.add_weight(name="att_bias", shape=(input_shape[-1],), initializer="zeros", trainable=True)

Â Â Â  def call(self, inputs):
Â Â Â Â Â Â Â  score = tf.nn.tanh(tf.matmul(inputs, self.W) + self.b)
Â Â Â Â Â Â Â  attention_weights = tf.nn.softmax(score, axis=1)
Â Â Â Â Â Â Â  context_vector = attention_weights * inputs
Â Â Â Â Â Â Â  context_vector = tf.reduce_sum(context_vector, axis=1)
Â Â Â Â Â Â Â  return context_vector

Â Â Â  def get_config(self):
Â Â Â Â Â Â Â  config = super().get_config()
Â Â Â Â Â Â Â  return config

Â Â Â  @classmethod
Â Â Â  def from_config(cls, config):
Â Â Â Â Â Â Â  return cls(**config)


def custom_loss(inputs, y_true, y_pred):
Â Â Â  mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))
Â Â Â  weights = tf.where(y_true > 0.5, 10.0, 1.0)
Â Â Â  weighted_mse_loss = tf.reduce_mean(weights * tf.square(y_true - y_pred))
Â Â Â  physics_loss = water_balance_loss(y_true, y_pred, inputs)
Â Â Â  return weighted_mse_loss + PHYSICS_LOSS_WEIGHT * physics_loss


class PINNModel(tf.keras.Model):
Â Â Â  def __init__(self, input_shape, gru_units=GRU_UNITS, dense_units_1=DENSE_UNITS_1, dense_units_2=DENSE_UNITS_2, dense_units_3=DENSE_UNITS_3, dropout_rate=DROPOUT_RATE, **kwargs): # Add hyperparameters as args
Â Â Â Â Â Â Â  super(PINNModel, self).__init__(**kwargs)
Â Â Â Â Â Â Â  self.gru_units = gru_units # Store hyperparameters
Â Â Â Â Â Â Â  self.dense_units_1 = dense_units_1
Â Â Â Â Â Â Â  self.dense_units_2 = dense_units_2
Â Â Â Â Â Â Â  self.dense_units_3 = dense_units_3
Â Â Â Â Â Â Â  self.dropout_rate = dropout_rate
Â Â Â Â Â Â Â  self.input_shape_arg = tuple(input_shape) # Ensure input_shape is stored as a tuple

Â Â Â Â Â Â Â  # Define layers in __init__
Â Â Â Â Â Â Â  self.inputs_PINN = tf.keras.layers.Input(shape=self.input_shape_arg) # Use stored tuple input_shape
Â Â Â Â Â Â Â  self.bidirectional_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(gru_units, return_sequences=True))
Â Â Â Â Â Â Â  self.attention = Attention()
Â Â Â Â Â Â Â  self.dense1 = tf.keras.layers.Dense(dense_units_1, activation='relu')
Â Â Â Â Â Â Â  self.bn1 = tf.keras.layers.BatchNormalization()
Â Â Â Â Â Â Â  self.dropout1 = tf.keras.layers.Dropout(dropout_rate)
Â Â Â Â Â Â Â  self.dense2 = tf.keras.layers.Dense(dense_units_2, activation='relu')
Â Â Â Â Â Â Â  self.bn2 = tf.keras.layers.BatchNormalization()
Â Â Â Â Â Â Â  self.dropout2 = tf.keras.layers.Dropout(dropout_rate)
Â Â Â Â Â Â Â  self.dense3 = tf.keras.layers.Dense(dense_units_3, activation='relu')
Â Â Â Â Â Â Â  self.output_layer = tf.keras.layers.Dense(1) # Output layer

Â Â Â  def call(self, inputs):
Â Â Â Â Â Â Â  x = self.inputs_PINN(inputs) # Apply input layer
Â Â Â Â Â Â Â  x = self.bidirectional_gru(x)
Â Â Â Â Â Â Â  x = self.attention(x)
Â Â Â Â Â Â Â  x = self.dense1(x)
Â Â Â Â Â Â Â  x = self.bn1(x)
Â Â Â Â Â Â Â  x = self.dropout1(x)
Â Â Â Â Â Â Â  x = self.dense2(x)
Â Â Â Â Â Â Â  x = self.bn2(x)
Â Â Â Â Â Â Â  x = self.dropout2(x)
Â Â Â Â Â Â Â  x = self.dense3(x)
Â Â Â Â Â Â Â  output = self.output_layer(x)
Â Â Â Â Â Â Â  return output

Â Â Â  def get_config(self):
Â Â Â Â Â Â Â  config = super().get_config()
Â Â Â Â Â Â Â  config.update({ # Serialize hyperparameters and input_shape
Â Â Â Â Â Â Â Â Â Â Â  'gru_units': self.gru_units,
Â Â Â Â Â Â Â Â Â Â Â  'dense_units_1': self.dense_units_1,
Â Â Â Â Â Â Â Â Â Â Â  'dense_units_2': self.dense_units_2,
Â Â Â Â Â Â Â Â Â Â Â  'dense_units_3': self.dense_units_3,
Â Â Â Â Â Â Â Â Â Â Â  'dropout_rate': self.dropout_rate,
Â Â Â Â Â Â Â Â Â Â Â  'input_shape': list(self.input_shape_arg) # Serialize input_shape as a list explicitly
Â Â Â Â Â Â Â  })
Â Â Â Â Â Â Â  return config

Â Â Â  @classmethod
Â Â Â  def from_config(cls, config):
Â Â Â Â Â Â Â  input_shape_list = config.pop('input_shape') # Get input_shape as a list from config
Â Â Â Â Â Â Â  input_shape = tuple(input_shape_list) # Convert list back to tuple
Â Â Â Â Â Â Â  return cls(input_shape=input_shape, **config) # Pass input_shape and other configs to constructor


# Streamlit App Title
st.title("ğŸŒŠ Streamflow Prediction Web App (PINN-GRU)")

# Upload Dataset
uploaded_file = st.file_uploader("ğŸ—‚ Upload an Excel file", type=["xlsx"])
if uploaded_file:
Â Â Â  df = pd.read_excel(uploaded_file)

Â Â Â  # Display dataset preview
Â Â Â  st.write("ğŸ“Š Preview of Dataset:", df.head())

Â Â Â  # Handle Date column
Â Â Â  if 'Date' in df.columns:
Â Â Â Â Â Â Â  df['Date'] = pd.to_datetime(df['Date'])
Â Â Â Â Â Â Â  df['Month'] = df['Date'].dt.month
Â Â Â Â Â Â Â  df['Month_sin'] = np.sin(2 * np.pi * df['Month'] / 12)
Â Â Â Â Â Â Â  df['Month_cos'] = np.cos(2 * np.pi * df['Month'] / 12)
Â Â Â Â Â Â Â  df.drop(columns=['Date'], inplace=True)

Â Â Â  # Handle missing values - Fill NaN values with 0
Â Â Â  df.fillna(0, inplace=True)

Â Â Â  # Select Features & Target
Â Â Â  target = 'Discharge (mÂ³/S)'
Â Â Â  dynamic_feature_cols = ['Rainfall (mm)', 'Maximum temperature (Â°C)', 'Minimum temperature (Â°C)'] # HydroMet Features
Â Â Â  features = [col for col in df.columns if col != target and col in dynamic_feature_cols] # Initial HydroMet features

Â Â Â  # Add Lag Features for Discharge and HydroMet Features
Â Â Â  lagged_discharge_cols = [f'Lag_Discharge_{i}' for i in range(1, NUM_LAGGED_FEATURES + 1)]
Â Â Â  lagged_weather_cols = [f'Lag_Rainfall_{i}' for i in range(1, NUM_LAGGED_FEATURES + 1)] + \
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  [f'Lag_TempMax_{i}' for i in range(1, NUM_LAGGED_FEATURES + 1)] + \
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  [f'Lag_TempMin_{i}' for i in range(1, NUM_LAGGED_FEATURES + 1)]
Â Â Â  seasonality_cols = ['Month_sin', 'Month_cos'] # Seasonality Features

Â Â Â  for lag in range(1, NUM_LAGGED_FEATURES + 1):
Â Â Â Â Â Â Â  df[f'Lag_Discharge_{lag}'] = df[target].shift(lag).fillna(0)
Â Â Â Â Â Â Â  if 'Rainfall (mm)' in df.columns:
Â Â Â Â Â Â Â Â Â Â Â  df[f'Lag_Rainfall_{lag}'] = df['Rainfall (mm)'].shift(lag).fillna(0)
Â Â Â Â Â Â Â  if 'Maximum temperature (Â°C)' in df.columns:
Â Â Â Â Â Â Â Â Â Â Â  df[f'Lag_TempMax_{lag}'] = df['Maximum temperature (Â°C)'].shift(lag).fillna(0)
Â Â Â Â Â Â Â  if 'Minimum temperature (Â°C)' in df.columns:
Â Â Â Â Â Â Â Â Â Â Â  df[f'Lag_TempMin_{lag}'] = df['Minimum temperature (Â°C)'].shift(lag).fillna(0)


Â Â Â  all_feature_cols = dynamic_feature_cols + lagged_discharge_cols + lagged_weather_cols + seasonality_cols
Â Â Â  features_for_model = [col for col in df.columns if col in all_feature_cols] # Ensure only available columns are used


Â Â Â  # Scaling
Â Â Â  scaler_dynamic = MinMaxScaler()
Â Â Â  scaler_y = MinMaxScaler()

Â Â Â  X_dynamic = df[features_for_model].values # Use selected features
Â Â Â  y_values = df[target].values

Â Â Â  X_dynamic_scaled = scaler_dynamic.fit_transform(X_dynamic)
Â Â Â  y_scaled = scaler_y.fit_transform(y_values.reshape(-1, 1))

Â Â Â  X_dynamic_scaled = X_dynamic_scaled.reshape((X_dynamic_scaled.shape[0], 1, X_dynamic_scaled.shape[1])) # Reshape for GRU


Â Â Â  # Train-Test Split (User-defined)
Â Â Â  train_split = st.slider("ğŸ¯ Select Training Data Percentage", 50, 90, 80) / 100
Â Â Â  X_train_dynamic, X_test_dynamic, y_train, y_test = train_test_split(X_dynamic_scaled, y_scaled, train_size=train_split, shuffle=False)
Â Â Â  st.write(f"ğŸ“Œ Train Data: {len(X_train_dynamic)}, Test Data: {len(X_test_dynamic)}")

Â Â Â  # User-defined epochs - Slider from 1 to 1000
Â Â Â  epochs = st.select_slider("â³ Set Number of Epochs:", options=EPOCH_RANGE, value=EPOCHS) # Epoch slider


Â Â Â  if st.button("ğŸš€ Train Model"):
Â Â Â Â Â Â Â  start_time = time.time()

Â Â Â Â Â Â Â  # Define PINN-GRU Model
Â Â Â Â Â Â Â  input_shape = (X_train_dynamic.shape[1], X_train_dynamic.shape[2]) # Define input shape here - TUPLE - Corrected input shape
Â Â Â Â Â Â Â  st.write(f"X_train_dynamic shape: {X_train_dynamic.shape}") # Debugging shape
Â Â Â Â Â Â Â  st.write(f"Input shape for PINNModel: {input_shape}") # Debugging input_shape
Â Â Â Â Â Â Â  model = PINNModel(input_shape=input_shape,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  gru_units=GRU_UNITS,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  dense_units_1=DENSE_UNITS_1,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  dense_units_2=DENSE_UNITS_2,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  dense_units_3=DENSE_UNITS_3,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  dropout_rate=DROPOUT_RATE) # Model creation - pass input_shape and hyperparameters

Â Â Â Â Â Â Â  # --- Debugging: Print config before saving ---
Â Â Â Â Â Â Â  config = model.get_config()
Â Â Â Â Â Â Â  st.write("Model Config Before Saving:")
Â Â Â Â Â Â Â  st.json(config) # Display config in Streamlit
Â Â Â Â Â Â Â  # ---------------------------------------------


Â Â Â Â Â Â Â  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=lambda y_true, y_pred: custom_loss(X_train_dynamic, y_true, y_pred), run_eagerly=True) # Keep run_eagerly=True for custom loss - Corrected Loss function
Â Â Â Â Â Â Â  lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=20, verbose=1)
Â Â Â Â Â Â Â  early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=250, min_delta=0.001, restore_best_weights=True)


Â Â Â Â Â Â Â  # Train the model
Â Â Â Â Â Â Â  history = model.fit(X_train_dynamic, y_train, epochs=epochs, batch_size=BATCH_SIZE, validation_data=(X_test_dynamic, y_test), verbose=1,
Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â Â  callbacks=[lr_scheduler, early_stopping])
Â Â Â Â Â Â Â  model.save("PINN_GRU_model.keras")


Â Â Â Â Â Â Â  training_time = time.time() - start_time
Â Â Â Â Â Â Â  st.write(f"âœ… PINN-GRU Model Trained in {training_time:.2f} seconds!")

Â Â Â  if st.button("ğŸ” Test Model"):
Â Â Â Â Â Â Â  test_start_time = time.time()

Â Â Â Â Â Â Â  model_path = "PINN_GRU_model.keras"

Â Â Â Â Â Â Â  if not os.path.exists(model_path):
Â Â Â Â Â Â Â Â Â Â Â  st.error(f"ğŸš¨ Error: Model file '{model_path}' not found! Please train the model first.")
Â Â Â Â Â Â Â Â Â Â Â  st.stop()

Â Â Â Â Â Â Â  # Load the trained model
Â Â Â Â Â Â Â  model = tf.keras.models.load_model(model_path, custom_objects={'Attention': Attention, 'PINNModel': PINNModel, 'custom_loss': custom_loss}) # Model loading
Â Â Â Â Â Â Â  y_pred = model.predict(X_test_dynamic)


Â Â Â Â Â Â Â  y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))
Â Â Â Â Â Â Â  y_actual = scaler_y.inverse_transform(y_test.reshape(-1, 1))

Â Â Â Â Â Â Â  # Compute Metrics
Â Â Â Â Â Â Â  rmse = np.sqrt(mean_squared_error(y_actual, y_pred))
Â Â Â Â Â Â Â  mae = mean_absolute_error(y_actual, y_pred)
Â Â Â Â Â Â Â  r2 = r2_score(y_actual, y_pred)
Â Â Â Â Â Â Â  test_time = time.time() - test_start_time

Â Â Â Â Â Â Â  st.write(f"ğŸ“‰ RMSE: {rmse:.4f}, MAE: {mae:.4f}, RÂ²: {r2:.4f}")
Â Â Â Â Â Â Â  st.write(f"â³ Testing Time: {test_time:.2f} seconds!")

Â Â Â Â Â Â Â  # Percentage difference calculation
Â Â Â Â Â Â Â  percentage_difference = np.abs((y_pred.flatten() - y_actual.flatten()) / y_actual.flatten()) * 100
Â Â Â Â Â Â Â  percentage_difference[np.isinf(percentage_difference)] = np.nanÂ  # Handle division by zero

Â Â Â Â Â Â Â  # User-defined acceptable percentage threshold
Â Â Â Â Â Â Â  acceptable_percentage_error = st.slider("ğŸ“‰ Acceptable Percentage Error Threshold", 1, 100, 20) # Slider for percentage

Â Â Â Â Â Â Â  # Count and display how many predictions are within the threshold
Â Â Â Â Â Â Â  within_threshold_count = np.sum(percentage_difference[~np.isnan(percentage_difference)] <= acceptable_percentage_error) # Exclude NaN values

Â Â Â Â Â Â Â  percentage_within_threshold = (within_threshold_count / len(y_actual)) * 100 if len(y_actual) > 0 else 0


Â Â Â Â Â Â Â  st.write(f"âœ… Predictions within Â±{acceptable_percentage_error}% error: {within_threshold_count} out of {len(y_actual)} ({percentage_within_threshold:.2f}%)")


Â Â Â Â Â Â Â  # Plot Predictions
Â Â Â Â Â Â Â  fig, ax = plt.subplots(figsize=(10, 5))
Â Â Â Â Â Â Â  ax.plot(y_actual, label="Actual", color="blue")
Â Â Â Â Â Â Â  ax.plot(y_pred, label="Predicted (PINN-GRU)", color="orange") # Model name in label
Â Â Â Â Â Â Â  ax.set_title("ğŸ“ˆ Actual vs. Predicted Streamflow (PINN-GRU)") # Model name in title
Â Â Â Â Â Â Â  ax.set_xlabel("Time")
Â Â Â Â Â Â Â  ax.set_ylabel("Streamflow (mÂ³/s)")
Â Â Â Â Â Â Â  ax.legend()
Â Â Â Â Â Â Â  st.pyplot(fig)

Â Â Â Â Â Â Â  # Save Predictions
Â Â Â Â Â Â Â  results_df = pd.DataFrame({"Actual": y_actual.flatten(), "Predicted (PINN-GRU)": y_pred.flatten()}) # Model name in column header
Â Â Â Â Â Â Â  results_df.to_csv("streamflow_predictions_pinn_gru.csv", index=False) # Model name in filename
Â Â Â Â Â Â Â  st.download_button("ğŸ“¥ Download Predictions", "streamflow_predictions_pinn_gru.csv", "text/csv")
